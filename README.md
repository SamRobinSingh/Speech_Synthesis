# 🗣️ Speech Synthesis AI Framework

## 🔍 Abstract

This research presents a conversational AI framework integrating **Speech-to-Text**, **Generative Text Modeling**, and **Text-to-Speech (TTS)** for seamless human-machine interaction. The pipeline is as follows:

- **Speech-to-Text**: Utilizes **OpenAI's Whisper** model to accurately transcribe human speech.
- **Generative Text Models**: Implements **Meta’s LLaMA 3.2** to generate coherent, context-aware responses from transcribed text.
- **Text-to-Speech**: Uses **Kokoro TTS**, an open-weight model, to convert the generated text into lifelike, expressive speech output.

This architecture ensures **high naturalness**, **consistency**, and **efficiency**, making it ideal for virtual assistants, accessibility tools, and real-time communication systems.

---

## 🚀 Features

- 🎙️ Real-time Speech Recognition with Whisper
- 🧠 Intelligent response generation using LLM (LLaMA 3.2)
- 🔊 Natural speech synthesis using Kokoro
- 📁 Modular design for easy extension and experimentation

---

## 🛠️ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/SamRobinSingh/Speech_Synthesis.git
   cd Speech_Synthesis
2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
3. **Install Chocolatey (Windows only)**
   Follow instructions: https://chocolatey.org/install
4. **Install FFmpeg (required for Whisper)**
   ```bash
   choco install ffmpeg
5. **Run the main program**
   ```bash
   python main.py





   
